{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae53a09-c04c-4916-a146-00e0bb188954",
   "metadata": {},
   "source": [
    "# L4: Support Data Insight Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08797e-0262-47f6-a5ba-0f933b06b06a",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c1339-5278-4daf-8e97-04c280bde548",
   "metadata": {},
   "source": [
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d1ce58-9d2e-4349-acbd-49227e37d31c",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "#from helper import load_env\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/home/jovyan/Albert/.env\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f583209-37a0-41a6-b5e8-3eee9c7127b6",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f336129-3c23-4ce8-a40b-3c1a15b232a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Dongping/crewai/L4\n"
     ]
    }
   ],
   "source": [
    "cd /home/jovyan/Dongping/crewai/L4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b574a-502a-49ec-9dc4-1e4e32754986",
   "metadata": {},
   "source": [
    "## Loading Tasks and Agents YAML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f171b23-b3cc-48c9-a8ba-07358e271e63",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "# Define file paths for YAML configurations\n",
    "files = {\n",
    "    'agents': '/home/jovyan/Dongping/crewai/L4/agents.yaml',\n",
    "    'tasks': '/home/jovyan/Dongping/crewai/L4/tasks.yaml'\n",
    "}\n",
    "\n",
    "# Load configurations from YAML files\n",
    "configs = {}\n",
    "for config_type, file_path in files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        configs[config_type] = yaml.safe_load(file)\n",
    "\n",
    "# Assign loaded configurations to specific variables\n",
    "agents_config = configs['agents']\n",
    "tasks_config = configs['tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfec7a50-4926-4179-8967-00c06add5133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agents': {'suggestion_generation_agent': {'role': 'Suggestion Engine\\n',\n",
       "   'goal': 'Generate actionable suggestions for resolving issues identified in the support tickets, leveraging historical data and predefined rules.\\n',\n",
       "   'backstory': 'You specialize in analyzing past resolutions and current issues to provide tailored suggestions that can help the support team resolve tickets efficiently.\\n',\n",
       "   'verbose': True,\n",
       "   'allow_delegation': False},\n",
       "  'reporting_agent': {'role': 'Report Generator\\n',\n",
       "   'goal': 'Compile a summary report that includes issue classification results, suggested actions, and key trends observed in the support data.\\n',\n",
       "   'backstory': 'You are skilled at transforming raw data into insightful reports that help stakeholders understand trends and make informed decisions.\\n',\n",
       "   'verbose': True,\n",
       "   'allow_delegation': False},\n",
       "  'chart_generation_agent': {'role': 'Chart Specialist\\n',\n",
       "   'goal': 'Create visual representations of the data provided by the Reporting Agent, including charts and graphs that effectively communicate key insights.\\n',\n",
       "   'backstory': 'You are a visualization expert, skilled at turning data into compelling visual stories that stakeholders can easily understand and act upon.\\n',\n",
       "   'verbose': True,\n",
       "   'allow_delegation': False}},\n",
       " 'tasks': {'suggestion_generation': {'description': 'Generate actionable suggestions for resolving each classified support ticket. The suggestions should be based on: - Issue Type: Tailor suggestions to the specific type of issue reported. - Historical Data: Use historical data such as resolution_time_minutes and\\n  satisfaction_rating to inform the suggestions.\\n- Customer Feedback: Incorporate insights from customer_comments to\\n  customize the suggestions further.\\n\\nThe goal is to provide clear, actionable steps that the support team can take to resolve each issue efficiently and effectively.\\n',\n",
       "   'expected_output': 'A list of actionable suggestions linked to each classified support ticket, optimized for quick and effective resolution by the support team.\\n'},\n",
       "  'table_generation': {'description': 'Generate tables that summarize the key metrics and trends observed in the support data, including: - Issue Classification Results: A table summarizing the frequency and\\n  priority levels of different issue types.\\n- Agent Performance: A table showing the performance of different agents\\n  based on resolution times and customer satisfaction scores.\\n- Customer Satisfaction: A table summarizing customer satisfaction ratings\\n  over time.\\n\\nThese tables will serve as the foundation for generating charts in the next task.\\n',\n",
       "   'expected_output': 'A set of tables summarizing the key metrics and trends observed in the support data, ready to be used for chart generation.\\n'},\n",
       "  'chart_generation': {'description': 'Generate charts based on the tables provided by the previous task. The charts should include: - Issue Distribution: A chart showing the distribution of different issue\\n  types.\\n- Priority Levels: A chart depicting the breakdown of tickets by priority\\n  level.\\n- Resolution Times: A trend line showing average resolution times over the\\n  past months.\\n- Customer Satisfaction: A bar chart or trend line showing customer\\n  satisfaction ratings over time.\\n- Agent Performance: A chart showing the performance of different agents\\n  based on resolution times and customer satisfaction scores.\\n\\nSave the charts as image files in the current directory.\\nEnsure that the charts are saved as image files, and generate URLs for these images so they can be easily embedded into the final report.\\n',\n",
       "   'expected_output': 'A set of charts that visually represent the key metrics and trends observed in the support data, ready to be integrated into the final report.\\n'},\n",
       "  'final_report_assembly': {'description': 'Assemble the final report by integrating the tables generated in the previous tasks. The report should include: - Issue Classification Results: Overview of the types of issues reported,\\n  their frequency, and priority levels, presented in tables.\\n- Agent Performance: Insights into the performance of support agents, based\\n  on metrics like resolution time and customer satisfaction, presented in\\n  tables.\\n- Customer Satisfaction: A summary of the customer satisfaction ratings and\\n  their trends over time, presented in tables.\\n- Suggested Actions: A summary of the actionable suggestions generated for\\n  each category of issue.\\n\\n\\nThe report should be formatted for easy consumption by stakeholders, providing valuable insights into the performance of the support system and areas for improvement.\\n',\n",
       "   'expected_output': \"A comprehensive final report that integrates tables, and actionable insights into a single document, formatted for stakeholders. Don't add '```' or '```markdown' to the report.\\n\"}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27064ec0-4a12-4dbd-b9b2-c77d4aaaedb5",
   "metadata": {},
   "source": [
    "## Using FileReadTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58e827a-8e2e-4f1d-8f8c-9486828f951d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from crewai_tools import FileReadTool\n",
    "csv_tool = FileReadTool(file_path='./support_tickets_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e31b3fac",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileReadTool(name=\"Read a file's content\", description=\"Tool Name: Read a file's content\\nTool Arguments: {}\\nTool Description: A tool that can be used to read ./support_tickets_data.csv's content.\", args_schema=<class 'crewai_tools.tools.file_read_tool.file_read_tool.FixedFileReadToolSchema'>, description_updated=False, cache_function=<function BaseTool.<lambda> at 0x7ff6c588d620>, result_as_answer=False, file_path='./support_tickets_data.csv')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96dba16b",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>issue_description</th>\n",
       "      <th>priority</th>\n",
       "      <th>date_submitted</th>\n",
       "      <th>response_time_minutes</th>\n",
       "      <th>resolution_time_minutes</th>\n",
       "      <th>satisfaction_rating</th>\n",
       "      <th>customer_comments</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>resolved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T0001</td>\n",
       "      <td>C0511</td>\n",
       "      <td>API Issue</td>\n",
       "      <td>I'm pleased with how my issue was handled. Tha...</td>\n",
       "      <td>High</td>\n",
       "      <td>2023-03-25</td>\n",
       "      <td>240</td>\n",
       "      <td>927</td>\n",
       "      <td>4</td>\n",
       "      <td>I'm pleased with how my issue was handled. Tha...</td>\n",
       "      <td>A004</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T0002</td>\n",
       "      <td>C0729</td>\n",
       "      <td>Login Issue</td>\n",
       "      <td>Excellent service! The agent went above and be...</td>\n",
       "      <td>Low</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>223</td>\n",
       "      <td>534</td>\n",
       "      <td>5</td>\n",
       "      <td>The problem still persists. Not resolved yet.</td>\n",
       "      <td>A004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T0003</td>\n",
       "      <td>C0439</td>\n",
       "      <td>Report Generation</td>\n",
       "      <td>Resolution was satisfactory but could be impro...</td>\n",
       "      <td>Low</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>214</td>\n",
       "      <td>592</td>\n",
       "      <td>1</td>\n",
       "      <td>The issue was escalated quickly, which was app...</td>\n",
       "      <td>A004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T0004</td>\n",
       "      <td>C0100</td>\n",
       "      <td>Data Import</td>\n",
       "      <td>Agent was very helpful and polite. Great service!</td>\n",
       "      <td>High</td>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>110</td>\n",
       "      <td>864</td>\n",
       "      <td>2</td>\n",
       "      <td>The issue was resolved quickly. Very satisfied!</td>\n",
       "      <td>A003</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T0005</td>\n",
       "      <td>C0258</td>\n",
       "      <td>Feature Request</td>\n",
       "      <td>My issue was handled well, but follow-up could...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>151</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>The problem still persists. Not resolved yet.</td>\n",
       "      <td>A004</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticket_id customer_id         issue_type  \\\n",
       "0     T0001       C0511          API Issue   \n",
       "1     T0002       C0729        Login Issue   \n",
       "2     T0003       C0439  Report Generation   \n",
       "3     T0004       C0100        Data Import   \n",
       "4     T0005       C0258    Feature Request   \n",
       "\n",
       "                                   issue_description priority date_submitted  \\\n",
       "0  I'm pleased with how my issue was handled. Tha...     High     2023-03-25   \n",
       "1  Excellent service! The agent went above and be...      Low     2023-04-06   \n",
       "2  Resolution was satisfactory but could be impro...      Low     2023-04-25   \n",
       "3  Agent was very helpful and polite. Great service!     High     2023-02-20   \n",
       "4  My issue was handled well, but follow-up could...   Medium     2023-01-18   \n",
       "\n",
       "   response_time_minutes  resolution_time_minutes  satisfaction_rating  \\\n",
       "0                    240                      927                    4   \n",
       "1                    223                      534                    5   \n",
       "2                    214                      592                    1   \n",
       "3                    110                      864                    2   \n",
       "4                    151                      193                    2   \n",
       "\n",
       "                                   customer_comments agent_id  resolved  \n",
       "0  I'm pleased with how my issue was handled. Tha...     A004      True  \n",
       "1      The problem still persists. Not resolved yet.     A004     False  \n",
       "2  The issue was escalated quickly, which was app...     A004     False  \n",
       "3    The issue was resolved quickly. Very satisfied!     A003      True  \n",
       "4      The problem still persists. Not resolved yet.     A004     False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./support_tickets_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf3ac13-e3be-468a-bab4-0930f825ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestion_generation_agent = Agent(\n",
    "  config=agents_config['suggestion_generation_agent'],\n",
    "  tools=[csv_tool]\n",
    ")\n",
    "\n",
    "reporting_agent = Agent(\n",
    "  config=agents_config['reporting_agent'],\n",
    "  tools=[csv_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc509e7-5aae-4795-a5f1-822cd5bfaefa",
   "metadata": {},
   "source": [
    "## Creating Agents, Tasks and Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d2c719-9823-4d12-bd87-219f5145f7dc",
   "metadata": {
    "height": 948
   },
   "outputs": [],
   "source": [
    "# Creating Agents\n",
    "suggestion_generation_agent = Agent(\n",
    "  config=agents_config['suggestion_generation_agent'],\n",
    "  tools=[csv_tool]\n",
    ")\n",
    "\n",
    "reporting_agent = Agent(\n",
    "  config=agents_config['reporting_agent'],\n",
    "  tools=[csv_tool]\n",
    ")\n",
    "\n",
    "#chart_generation_agent = Agent(\n",
    "#  config=agents_config['chart_generation_agent'],\n",
    "#  allow_code_execution=True\n",
    "#)\n",
    "\n",
    "# Creating Tasks\n",
    "suggestion_generation = Task(\n",
    "  config=tasks_config['suggestion_generation'],\n",
    "  agent=suggestion_generation_agent\n",
    ")\n",
    "\n",
    "table_generation = Task(\n",
    "  config=tasks_config['table_generation'],\n",
    "  agent=reporting_agent\n",
    ")\n",
    "\n",
    "#chart_generation = Task(\n",
    "#  config=tasks_config['chart_generation'],\n",
    "#  agent=chart_generation_agent\n",
    "#)\n",
    "\n",
    "final_report_assembly = Task(\n",
    "  config=tasks_config['final_report_assembly'],\n",
    "  agent=reporting_agent,\n",
    "  context=[suggestion_generation, table_generation]\n",
    "  #context=[suggestion_generation, table_generation, chart_generation]\n",
    ")\n",
    "\n",
    "\n",
    "# Creating Crew\n",
    "support_report_crew = Crew(\n",
    "  agents=[\n",
    "    suggestion_generation_agent,\n",
    "    reporting_agent\n",
    "  ],\n",
    "  tasks=[\n",
    "    suggestion_generation,\n",
    "    table_generation,\n",
    "    final_report_assembly\n",
    "  ],\n",
    "  verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299bca36-395b-45f2-92e7-27b403e32a27",
   "metadata": {},
   "source": [
    "## Testing our Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6646acc-e280-44cc-8968-08db37115eba",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 09:34:03,864 - 140698965987392 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n",
      "2024-12-02 09:34:04,073 - 140698965987392 - llm.py-llm:170 - ERROR: LiteLLM call failed: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSuggestion Engine\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mGenerate actionable suggestions for resolving each classified support ticket. The suggestions should be based on: - Issue Type: Tailor suggestions to the specific type of issue reported. - Historical Data: Use historical data such as resolution_time_minutes and\n",
      "  satisfaction_rating to inform the suggestions.\n",
      "- Customer Feedback: Incorporate insights from customer_comments to\n",
      "  customize the suggestions further.\n",
      "\n",
      "The goal is to provide clear, actionable steps that the support team can take to resolve each issue efficiently and effectively.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSuggestion Engine\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mGenerate actionable suggestions for resolving each classified support ticket. The suggestions should be based on: - Issue Type: Tailor suggestions to the specific type of issue reported. - Historical Data: Use historical data such as resolution_time_minutes and\n",
      "  satisfaction_rating to inform the suggestions.\n",
      "- Customer Feedback: Incorporate insights from customer_comments to\n",
      "  customize the suggestions further.\n",
      "\n",
      "The goal is to provide clear, actionable steps that the support team can take to resolve each issue efficiently and effectively.\n",
      "\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 09:34:04,199 - 140698965987392 - llm.py-llm:170 - ERROR: LiteLLM call failed: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n",
      "    return convert_to_model_response_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n",
      "    raise Exception(\n",
      "Exception: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n",
      "    response = openai_chat_completions.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n",
      "    result = self.agent_executor.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n",
      "    formatted_answer = self._invoke_loop()\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n",
      "    answer = self.llm.call(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n",
      "    response = litellm.completion(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n",
      "    result = original_function(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n",
      "    raise exception_type(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "2024-12-02 09:34:04,287 - 140698965987392 - llm.py-llm:170 - ERROR: LiteLLM call failed: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n",
      "    return convert_to_model_response_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n",
      "    raise Exception(\n",
      "Exception: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n",
      "    response = openai_chat_completions.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n",
      "    result = self.agent_executor.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n",
      "    formatted_answer = self._invoke_loop()\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n",
      "    answer = self.llm.call(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n",
      "    response = litellm.completion(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n",
      "    result = original_function(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n",
      "    raise exception_type(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n",
      "    return convert_to_model_response_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n",
      "    raise Exception(\n",
      "Exception: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n",
      "    return convert_to_model_response_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n",
      "    raise Exception(\n",
      "Exception: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n",
      "    response = openai_chat_completions.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n",
      "    result = self.agent_executor.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n",
      "    formatted_answer = self._invoke_loop()\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n",
      "    answer = self.llm.call(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n",
      "    response = litellm.completion(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n",
      "    result = original_function(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n",
      "    raise exception_type(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n",
      "    response = openai_chat_completions.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n",
      "    return convert_to_model_response_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n",
      "    raise Exception(\n",
      "Exception: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n",
      "    response = openai_chat_completions.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n",
      "    result = self.agent_executor.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n",
      "    formatted_answer = self._invoke_loop()\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n",
      "    answer = self.llm.call(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n",
      "    response = litellm.completion(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n",
      "    result = original_function(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n",
      "    raise exception_type(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n",
      "    result = self.agent_executor.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n",
      "    formatted_answer = self._invoke_loop()\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n",
      "    answer = self.llm.call(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n",
      "    response = litellm.completion(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n",
      "    result = original_function(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n",
      "    raise exception_type(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n",
      "    return convert_to_model_response_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n",
      "    raise Exception(\n",
      "Exception: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n",
      "    response = openai_chat_completions.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n",
      "    raise OpenAIError(\n",
      "litellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n",
      "    result = self.agent_executor.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n",
      "    formatted_answer = self._invoke_loop()\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n",
      "    answer = self.llm.call(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n",
      "    response = litellm.completion(**params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n",
      "    result = original_function(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n",
      "    raise exception_type(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n",
      "    raise e\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n",
      "    raise APIError(\n",
      "litellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n",
      "    assert response_object[\"choices\"] is not None and isinstance(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "\n",
      "received_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '0b7c0618516f4228859cd27e86c461bf', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-22c55ead-5ad2-4947-ae5d-6951a4a41707', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSuggestion Engine\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mGenerate actionable suggestions for resolving each classified support ticket. The suggestions should be based on: - Issue Type: Tailor suggestions to the specific type of issue reported. - Historical Data: Use historical data such as resolution_time_minutes and\n",
      "  satisfaction_rating to inform the suggestions.\n",
      "- Customer Feedback: Incorporate insights from customer_comments to\n",
      "  customize the suggestions further.\n",
      "\n",
      "The goal is to provide clear, actionable steps that the support team can take to resolve each issue efficiently and effectively.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '0b7c0618516f4228859cd27e86c461bf', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-22c55ead-5ad2-4947-ae5d-6951a4a41707', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py:380\u001b[0m, in \u001b[0;36mconvert_to_model_response_object\u001b[0;34m(response_object, model_response_object, response_type, stream, start_time, end_time, hidden_params, _response_headers, convert_tool_call_to_json_mode)\u001b[0m\n\u001b[1;32m    378\u001b[0m choice_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    381\u001b[0m     response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m], Iterable\n\u001b[1;32m    382\u001b[0m )\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, choice \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m## HANDLE JSON MODE - anthropic returns single function call]\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:860\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:811\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    805\u001b[0m         logging_obj\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m    806\u001b[0m             \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    807\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m    808\u001b[0m             original_response\u001b[38;5;241m=\u001b[39mstringified_response,\n\u001b[1;32m    809\u001b[0m             additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete_input_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: data},\n\u001b[1;32m    810\u001b[0m         )\n\u001b[0;32m--> 811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_model_response_object(\n\u001b[1;32m    812\u001b[0m             response_object\u001b[38;5;241m=\u001b[39mstringified_response,\n\u001b[1;32m    813\u001b[0m             model_response_object\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[1;32m    814\u001b[0m             _response_headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    815\u001b[0m         )\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mUnprocessableEntityError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m## check if body contains unprocessable params - related issue https://github.com/BerriAI/litellm/issues/4800\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py:583\u001b[0m, in \u001b[0;36mconvert_to_model_response_object\u001b[0;34m(response_object, model_response_object, response_type, stream, start_time, end_time, hidden_params, _response_headers, convert_tool_call_to_json_mode)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid response object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mreceived_args=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:1605\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m   1600\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1601\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1602\u001b[0m         original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m   1603\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[1;32m   1604\u001b[0m     )\n\u001b[0;32m-> 1605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:1578\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1578\u001b[0m         response \u001b[38;5;241m=\u001b[39m openai_chat_completions\u001b[38;5;241m.\u001b[39mcompletion(\n\u001b[1;32m   1579\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1580\u001b[0m             messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1581\u001b[0m             headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1582\u001b[0m             model_response\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[1;32m   1583\u001b[0m             print_verbose\u001b[38;5;241m=\u001b[39mprint_verbose,\n\u001b[1;32m   1584\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1585\u001b[0m             api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[1;32m   1586\u001b[0m             acompletion\u001b[38;5;241m=\u001b[39macompletion,\n\u001b[1;32m   1587\u001b[0m             logging_obj\u001b[38;5;241m=\u001b[39mlogging,\n\u001b[1;32m   1588\u001b[0m             optional_params\u001b[38;5;241m=\u001b[39moptional_params,\n\u001b[1;32m   1589\u001b[0m             litellm_params\u001b[38;5;241m=\u001b[39mlitellm_params,\n\u001b[1;32m   1590\u001b[0m             logger_fn\u001b[38;5;241m=\u001b[39mlogger_fn,\n\u001b[1;32m   1591\u001b[0m             timeout\u001b[38;5;241m=\u001b[39mtimeout,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m             custom_prompt_dict\u001b[38;5;241m=\u001b[39mcustom_prompt_dict,\n\u001b[1;32m   1593\u001b[0m             client\u001b[38;5;241m=\u001b[39mclient,  \u001b[38;5;66;03m# pass AsyncOpenAI, OpenAI client\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m             organization\u001b[38;5;241m=\u001b[39morganization,\n\u001b[1;32m   1595\u001b[0m             custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   1596\u001b[0m         )\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:870\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 870\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    871\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code, message\u001b[38;5;241m=\u001b[39merror_text, headers\u001b[38;5;241m=\u001b[39merror_headers\n\u001b[1;32m    872\u001b[0m )\n",
      "\u001b[0;31mOpenAIError\u001b[0m: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py:297\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    298\u001b[0m         {\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: task_prompt,\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_names,\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_description,\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: task\u001b[38;5;241m.\u001b[39mhuman_input,\n\u001b[1;32m    303\u001b[0m         }\n\u001b[1;32m    304\u001b[0m     )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:93\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m---> 93\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_loop()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:185\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_logs(formatted_answer)\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:115\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit():\n\u001b[0;32m--> 115\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages,\n\u001b[1;32m    117\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py:164\u001b[0m, in \u001b[0;36mLLM.call\u001b[0;34m(self, messages, callbacks)\u001b[0m\n\u001b[1;32m    162\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m--> 164\u001b[0m response \u001b[38;5;241m=\u001b[39m litellm\u001b[38;5;241m.\u001b[39mcompletion(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py:960\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m    958\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m    959\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py:849\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    850\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:3059\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3058\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 3059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[1;32m   3060\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   3061\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   3062\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   3063\u001b[0m         completion_kwargs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   3064\u001b[0m         extra_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   3065\u001b[0m     )\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2136\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[0;32m-> 2136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:404\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m         exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m APIError(\n\u001b[1;32m    405\u001b[0m             status_code\u001b[38;5;241m=\u001b[39moriginal_exception\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    406\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPIError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    407\u001b[0m             llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m    408\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    409\u001b[0m             request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    410\u001b[0m             litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# if no status code then it is an APIConnectionError: https://github.com/openai/openai-python#handling-errors\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# exception_mapping_worked = True\u001b[39;00m\n",
      "\u001b[0;31mAPIError\u001b[0m: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py:380\u001b[0m, in \u001b[0;36mconvert_to_model_response_object\u001b[0;34m(response_object, model_response_object, response_type, stream, start_time, end_time, hidden_params, _response_headers, convert_tool_call_to_json_mode)\u001b[0m\n\u001b[1;32m    378\u001b[0m choice_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    381\u001b[0m     response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m], Iterable\n\u001b[1;32m    382\u001b[0m )\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, choice \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m## HANDLE JSON MODE - anthropic returns single function call]\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:860\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:811\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    805\u001b[0m         logging_obj\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m    806\u001b[0m             \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    807\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m    808\u001b[0m             original_response\u001b[38;5;241m=\u001b[39mstringified_response,\n\u001b[1;32m    809\u001b[0m             additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete_input_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: data},\n\u001b[1;32m    810\u001b[0m         )\n\u001b[0;32m--> 811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_model_response_object(\n\u001b[1;32m    812\u001b[0m             response_object\u001b[38;5;241m=\u001b[39mstringified_response,\n\u001b[1;32m    813\u001b[0m             model_response_object\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[1;32m    814\u001b[0m             _response_headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    815\u001b[0m         )\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mUnprocessableEntityError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m## check if body contains unprocessable params - related issue https://github.com/BerriAI/litellm/issues/4800\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py:583\u001b[0m, in \u001b[0;36mconvert_to_model_response_object\u001b[0;34m(response_object, model_response_object, response_type, stream, start_time, end_time, hidden_params, _response_headers, convert_tool_call_to_json_mode)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid response object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mreceived_args=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:1605\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m   1600\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1601\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1602\u001b[0m         original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m   1603\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[1;32m   1604\u001b[0m     )\n\u001b[0;32m-> 1605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:1578\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1578\u001b[0m         response \u001b[38;5;241m=\u001b[39m openai_chat_completions\u001b[38;5;241m.\u001b[39mcompletion(\n\u001b[1;32m   1579\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1580\u001b[0m             messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1581\u001b[0m             headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1582\u001b[0m             model_response\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[1;32m   1583\u001b[0m             print_verbose\u001b[38;5;241m=\u001b[39mprint_verbose,\n\u001b[1;32m   1584\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1585\u001b[0m             api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[1;32m   1586\u001b[0m             acompletion\u001b[38;5;241m=\u001b[39macompletion,\n\u001b[1;32m   1587\u001b[0m             logging_obj\u001b[38;5;241m=\u001b[39mlogging,\n\u001b[1;32m   1588\u001b[0m             optional_params\u001b[38;5;241m=\u001b[39moptional_params,\n\u001b[1;32m   1589\u001b[0m             litellm_params\u001b[38;5;241m=\u001b[39mlitellm_params,\n\u001b[1;32m   1590\u001b[0m             logger_fn\u001b[38;5;241m=\u001b[39mlogger_fn,\n\u001b[1;32m   1591\u001b[0m             timeout\u001b[38;5;241m=\u001b[39mtimeout,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m             custom_prompt_dict\u001b[38;5;241m=\u001b[39mcustom_prompt_dict,\n\u001b[1;32m   1593\u001b[0m             client\u001b[38;5;241m=\u001b[39mclient,  \u001b[38;5;66;03m# pass AsyncOpenAI, OpenAI client\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m             organization\u001b[38;5;241m=\u001b[39morganization,\n\u001b[1;32m   1595\u001b[0m             custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   1596\u001b[0m         )\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:870\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 870\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    871\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code, message\u001b[38;5;241m=\u001b[39merror_text, headers\u001b[38;5;241m=\u001b[39merror_headers\n\u001b[1;32m    872\u001b[0m )\n",
      "\u001b[0;31mOpenAIError\u001b[0m: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py:297\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    298\u001b[0m         {\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: task_prompt,\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_names,\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_description,\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: task\u001b[38;5;241m.\u001b[39mhuman_input,\n\u001b[1;32m    303\u001b[0m         }\n\u001b[1;32m    304\u001b[0m     )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:93\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m---> 93\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_loop()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:185\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_logs(formatted_answer)\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:115\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit():\n\u001b[0;32m--> 115\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages,\n\u001b[1;32m    117\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py:164\u001b[0m, in \u001b[0;36mLLM.call\u001b[0;34m(self, messages, callbacks)\u001b[0m\n\u001b[1;32m    162\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m--> 164\u001b[0m response \u001b[38;5;241m=\u001b[39m litellm\u001b[38;5;241m.\u001b[39mcompletion(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py:960\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m    958\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m    959\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py:849\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    850\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:3059\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3058\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 3059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[1;32m   3060\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   3061\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   3062\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   3063\u001b[0m         completion_kwargs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   3064\u001b[0m         extra_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   3065\u001b[0m     )\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2136\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[0;32m-> 2136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:404\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m         exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m APIError(\n\u001b[1;32m    405\u001b[0m             status_code\u001b[38;5;241m=\u001b[39moriginal_exception\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    406\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPIError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    407\u001b[0m             llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m    408\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    409\u001b[0m             request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    410\u001b[0m             litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# if no status code then it is an APIConnectionError: https://github.com/openai/openai-python#handling-errors\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# exception_mapping_worked = True\u001b[39;00m\n",
      "\u001b[0;31mAPIError\u001b[0m: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py:380\u001b[0m, in \u001b[0;36mconvert_to_model_response_object\u001b[0;34m(response_object, model_response_object, response_type, stream, start_time, end_time, hidden_params, _response_headers, convert_tool_call_to_json_mode)\u001b[0m\n\u001b[1;32m    378\u001b[0m choice_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    381\u001b[0m     response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m], Iterable\n\u001b[1;32m    382\u001b[0m )\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, choice \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(response_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m## HANDLE JSON MODE - anthropic returns single function call]\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:860\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:811\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    805\u001b[0m         logging_obj\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m    806\u001b[0m             \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    807\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m    808\u001b[0m             original_response\u001b[38;5;241m=\u001b[39mstringified_response,\n\u001b[1;32m    809\u001b[0m             additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete_input_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: data},\n\u001b[1;32m    810\u001b[0m         )\n\u001b[0;32m--> 811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_model_response_object(\n\u001b[1;32m    812\u001b[0m             response_object\u001b[38;5;241m=\u001b[39mstringified_response,\n\u001b[1;32m    813\u001b[0m             model_response_object\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[1;32m    814\u001b[0m             _response_headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    815\u001b[0m         )\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mUnprocessableEntityError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m## check if body contains unprocessable params - related issue https://github.com/BerriAI/litellm/issues/4800\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py:583\u001b[0m, in \u001b[0;36mconvert_to_model_response_object\u001b[0;34m(response_object, model_response_object, response_type, stream, start_time, end_time, hidden_params, _response_headers, convert_tool_call_to_json_mode)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid response object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mreceived_args=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '0b7c0618516f4228859cd27e86c461bf', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-22c55ead-5ad2-4947-ae5d-6951a4a41707', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:1605\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m   1600\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1601\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1602\u001b[0m         original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m   1603\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[1;32m   1604\u001b[0m     )\n\u001b[0;32m-> 1605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:1578\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1578\u001b[0m         response \u001b[38;5;241m=\u001b[39m openai_chat_completions\u001b[38;5;241m.\u001b[39mcompletion(\n\u001b[1;32m   1579\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1580\u001b[0m             messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   1581\u001b[0m             headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1582\u001b[0m             model_response\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[1;32m   1583\u001b[0m             print_verbose\u001b[38;5;241m=\u001b[39mprint_verbose,\n\u001b[1;32m   1584\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m   1585\u001b[0m             api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[1;32m   1586\u001b[0m             acompletion\u001b[38;5;241m=\u001b[39macompletion,\n\u001b[1;32m   1587\u001b[0m             logging_obj\u001b[38;5;241m=\u001b[39mlogging,\n\u001b[1;32m   1588\u001b[0m             optional_params\u001b[38;5;241m=\u001b[39moptional_params,\n\u001b[1;32m   1589\u001b[0m             litellm_params\u001b[38;5;241m=\u001b[39mlitellm_params,\n\u001b[1;32m   1590\u001b[0m             logger_fn\u001b[38;5;241m=\u001b[39mlogger_fn,\n\u001b[1;32m   1591\u001b[0m             timeout\u001b[38;5;241m=\u001b[39mtimeout,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m             custom_prompt_dict\u001b[38;5;241m=\u001b[39mcustom_prompt_dict,\n\u001b[1;32m   1593\u001b[0m             client\u001b[38;5;241m=\u001b[39mclient,  \u001b[38;5;66;03m# pass AsyncOpenAI, OpenAI client\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m             organization\u001b[38;5;241m=\u001b[39morganization,\n\u001b[1;32m   1595\u001b[0m             custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   1596\u001b[0m         )\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py:870\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 870\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    871\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code, message\u001b[38;5;241m=\u001b[39merror_text, headers\u001b[38;5;241m=\u001b[39merror_headers\n\u001b[1;32m    872\u001b[0m )\n",
      "\u001b[0;31mOpenAIError\u001b[0m: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.OpenAIError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '0b7c0618516f4228859cd27e86c461bf', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-22c55ead-5ad2-4947-ae5d-6951a4a41707', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m support_report_crew\u001b[38;5;241m.\u001b[39mtest(n_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, openai_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/crew.py:1052\u001b[0m, in \u001b[0;36mCrew.test\u001b[0;34m(self, n_iterations, openai_model_name, inputs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_iterations \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1051\u001b[0m     evaluator\u001b[38;5;241m.\u001b[39mset_iteration(i)\n\u001b[0;32m-> 1052\u001b[0m     test_crew\u001b[38;5;241m.\u001b[39mkickoff(inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m   1054\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mprint_crew_evaluation_result()\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/crew.py:540\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    537\u001b[0m metrics: List[UsageMetrics] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 540\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sequential_process()\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    542\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/crew.py:647\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrewOutput:\n\u001b[1;32m    646\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_tasks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks)\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/crew.py:745\u001b[0m, in \u001b[0;36mCrew._execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    742\u001b[0m     futures\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    744\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_context(task, task_outputs)\n\u001b[0;32m--> 745\u001b[0m task_output \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mexecute_sync(\n\u001b[1;32m    746\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent_to_use,\n\u001b[1;32m    747\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    748\u001b[0m     tools\u001b[38;5;241m=\u001b[39magent_to_use\u001b[38;5;241m.\u001b[39mtools,\n\u001b[1;32m    749\u001b[0m )\n\u001b[1;32m    750\u001b[0m task_outputs \u001b[38;5;241m=\u001b[39m [task_output]\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_task_result(task, task_output)\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/task.py:192\u001b[0m, in \u001b[0;36mTask.execute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_sync\u001b[39m(\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    187\u001b[0m     agent: Optional[BaseAgent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    188\u001b[0m     context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m     tools: Optional[List[BaseTool]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskOutput:\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_core(agent, context, tools)\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/task.py:250\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    246\u001b[0m tools \u001b[38;5;241m=\u001b[39m tools \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_by_agents\u001b[38;5;241m.\u001b[39madd(agent\u001b[38;5;241m.\u001b[39mrole)\n\u001b[0;32m--> 250\u001b[0m result \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mexecute_task(\n\u001b[1;32m    251\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    252\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    253\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    254\u001b[0m )\n\u001b[1;32m    256\u001b[0m pydantic_output, json_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    258\u001b[0m task_output \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    259\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    260\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_format(),\n\u001b[1;32m    267\u001b[0m )\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py:309\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retry_limit:\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 309\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_task(task, context, tools)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller\u001b[38;5;241m.\u001b[39mstop_rpm_counter()\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py:309\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retry_limit:\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 309\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_task(task, context, tools)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller\u001b[38;5;241m.\u001b[39mstop_rpm_counter()\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py:308\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retry_limit:\n\u001b[0;32m--> 308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    309\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_task(task, context, tools)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rpm_controller:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py:297\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    294\u001b[0m     task_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_trained_data(task_prompt\u001b[38;5;241m=\u001b[39mtask_prompt)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    298\u001b[0m         {\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: task_prompt,\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_names,\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39mtools_description,\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: task\u001b[38;5;241m.\u001b[39mhuman_input,\n\u001b[1;32m    303\u001b[0m         }\n\u001b[1;32m    304\u001b[0m     )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:93\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_start_logs()\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m---> 93\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_loop()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input:\n\u001b[1;32m     96\u001b[0m     human_feedback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ask_human_input(formatted_answer\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:185\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_loop(formatted_answer)\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_logs(formatted_answer)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_answer\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py:115\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentFinish):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_within_rpm_limit():\n\u001b[0;32m--> 115\u001b[0m         answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages,\n\u001b[1;32m    117\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    122\u001b[0m                 content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived None or empty response from LLM call.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    123\u001b[0m                 color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    124\u001b[0m             )\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py:164\u001b[0m, in \u001b[0;36mLLM.call\u001b[0;34m(self, messages, callbacks)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Remove None values to avoid passing unnecessary parameters\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m--> 164\u001b[0m     response \u001b[38;5;241m=\u001b[39m litellm\u001b[38;5;241m.\u001b[39mcompletion(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py:960\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[1;32m    957\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m    958\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m    959\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py:849\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    847\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    850\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py:3059\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   3056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3058\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 3059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[1;32m   3060\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   3061\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   3062\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   3063\u001b[0m         completion_kwargs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   3064\u001b[0m         extra_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   3065\u001b[0m     )\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2136\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[0;32m-> 2136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mLITELLM_EXCEPTION_TYPES:\n",
      "File \u001b[0;32m~/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:404\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m APIError(\n\u001b[1;32m    405\u001b[0m             status_code\u001b[38;5;241m=\u001b[39moriginal_exception\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    406\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPIError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    407\u001b[0m             llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m    408\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    409\u001b[0m             request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    410\u001b[0m             litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# if no status code then it is an APIConnectionError: https://github.com/openai/openai-python#handling-errors\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# exception_mapping_worked = True\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[1;32m    416\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPIConnectionError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    417\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m         ),\n\u001b[1;32m    423\u001b[0m     )\n",
      "\u001b[0;31mAPIError\u001b[0m: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 860, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 811, in completion\n    return convert_to_model_response_object(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 583, in convert_to_model_response_object\n    raise Exception(\nException: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1605, in completion\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 1578, in completion\n    response = openai_chat_completions.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/llms/OpenAI/openai.py\", line 870, in completion\n    raise OpenAIError(\nlitellm.llms.OpenAI.openai.openaiError: Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agent.py\", line 297, in execute_task\n    result = self.agent_executor.invoke(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 93, in invoke\n    formatted_answer = self._invoke_loop()\n                       ^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 185, in _invoke_loop\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/agents/crew_agent_executor.py\", line 115, in _invoke_loop\n    answer = self.llm.call(\n             ^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/crewai/llm.py\", line 164, in call\n    response = litellm.completion(**params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 960, in wrapper\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/utils.py\", line 849, in wrapper\n    result = original_function(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/main.py\", line 3059, in completion\n    raise exception_type(\n          ^^^^^^^^^^^^^^^\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2136, in exception_type\n    raise e\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 404, in exception_type\n    raise APIError(\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Invalid response object Traceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '4261fbc526114e70991d8f911c3e62b6', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-787b246e-1fe9-4698-bad7-1bf514f217cc', created=1733132043, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '61', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '84b879ee117741db99887a1b2890434d', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-9cd9ecd9-4512-42c5-b450-d22118304ee1', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/jovyan/envs/llm_agent_crewai/lib/python3.11/site-packages/litellm/litellm_core_utils/llm_response_utils/convert_dict_to_response.py\", line 380, in convert_to_model_response_object\n    assert response_object[\"choices\"] is not None and isinstance(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n\n\nreceived_args={'response_object': {'id': None, 'choices': None, 'created': None, 'model': None, 'object': None, 'service_tier': None, 'system_fingerprint': None, 'usage': None, 'llm-gateway-requestid': '0b7c0618516f4228859cd27e86c461bf', 'responseCode': 501, 'responseDesc': 'LLM Request Failed', 'Error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'deployment_name': 'gpt-4o-mini'}, 'model_response_object': ModelResponse(id='chatcmpl-22c55ead-5ad2-4947-ae5d-6951a4a41707', created=1733132044, model=None, object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=None, role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0, completion_tokens_details=None, prompt_tokens_details=None)), 'response_type': 'completion', 'stream': False, 'start_time': None, 'end_time': None, 'hidden_params': None, '_response_headers': {'date': 'Mon, 02 Dec 2024 09:34:04 GMT', 'content-type': 'application/json', 'content-length': '377', 'connection': 'keep-alive', 'x-envoy-upstream-service-time': '51', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}, 'convert_tool_call_to_json_mode': None}"
     ]
    }
   ],
   "source": [
    "support_report_crew.test(n_iterations=1, openai_model_name='gpt-4o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1fa2c2-6256-4420-8b7b-c8d5e09bbc01",
   "metadata": {},
   "source": [
    "## Training your crew and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e362d-c010-43dd-88c4-e7db87834fb4",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "support_report_crew.train(n_iterations=1, filename='training.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e94a74-8700-4f83-b732-01b8d63dd774",
   "metadata": {},
   "source": [
    "## Comparing new test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc73842-8162-49f9-b4a1-5dc7d86f3e48",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "support_report_crew.test(n_iterations=1, openai_model_name='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8626d2-e48a-4b7e-a061-a8eb492c9036",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Display the Trello screenshot\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Load and display the image\n",
    "test_image = Image(filename='test_before_training.png', width=368)\n",
    "display(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1437cf-ebc1-4e46-b982-7eeec5462479",
   "metadata": {},
   "source": [
    "## Kicking off Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655927f-c10c-4c06-852a-d9c96fdfbfb9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = support_report_crew.kickoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039f919-2d28-4871-b316-8813e9adebde",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e861574-0f9b-4f2c-b2d1-a230fc3a53a3",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(result.raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a951d6a-8363-44f4-8783-e8397f435a32",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40b53e-0a49-4198-a263-c79a6a3af603",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb6a8a-7ae7-4ae6-99a7-92aa09d97d7f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3b165-2a4b-46cc-93f7-696dffff1e10",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2a2af-3e55-4de9-86bb-d33c21ade238",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109926d3-50e5-43e7-87f8-a1d38e45d79d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jovyan-llm_agent_crewai]",
   "language": "python",
   "name": "conda-env-jovyan-llm_agent_crewai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
